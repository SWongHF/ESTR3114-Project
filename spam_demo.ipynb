{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "import sklearn.metrics\n",
    "import sklearn.svm\n",
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OGDOptimizer\n",
    "class OGDOptimizer(torch.optim.Optimizer):\n",
    "\n",
    "    # Init Method:\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "        super(OGDOptimizer, self).__init__(params, defaults={\"lr\": lr})\n",
    "        self.state = dict()\n",
    "\n",
    "    # Step Method\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                p.data = p.data - group[\"lr\"] * p.grad.data\n",
    "\n",
    "\n",
    "class LinearLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        loss = torch.max(torch.tensor(0), 1 - target * inputs)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601\n",
      "0.6057378830688981\n"
     ]
    }
   ],
   "source": [
    "mat = scipy.io.loadmat(\"spam_data.mat\")\n",
    "spam_inst = mat[\"spam_inst\"]\n",
    "spam_label = mat[\"spam_label\"][:, 0]\n",
    "\n",
    "\n",
    "T = len(spam_label)\n",
    "print(T)\n",
    "B = 2\n",
    "L = 1\n",
    "\n",
    "eta = 2 / (math.sqrt(2 * T))\n",
    "known_spam_inst = []\n",
    "known_spam_label = []\n",
    "class_n = 0\n",
    "class_p = 0\n",
    "prediction = []\n",
    "cum_loss=0\n",
    "# FTRL\n",
    "for i in range(len(spam_label)):\n",
    "    if (class_n > 0) + (class_p > 0) != 2:\n",
    "        if spam_label[i] == -1:\n",
    "            class_n += 1\n",
    "        else:\n",
    "            class_p += 1\n",
    "        if class_n > class_p:\n",
    "            prediction.append(-1)\n",
    "        else:\n",
    "            prediction.append(1)\n",
    "    else:\n",
    "        model = sklearn.svm.LinearSVC(loss=\"hinge\", C=eta, dual=\"auto\")\n",
    "        model.fit(np.array(known_spam_inst), np.array(known_spam_label))\n",
    "        p = model.predict(spam_inst[i].reshape(1, -1))\n",
    "        prediction.append(p[0])\n",
    "\n",
    "    known_spam_inst.append(spam_inst[i])\n",
    "    known_spam_label.append(spam_label[i])\n",
    "\n",
    "print(sklearn.metrics.accuracy_score(spam_label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_45640\\758162792.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spam_inst=torch.tensor(spam_inst).requires_grad_(True)\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_45640\\758162792.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spam_label=torch.tensor(spam_label,dtype=float).requires_grad_(True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605520539013258\n"
     ]
    }
   ],
   "source": [
    "w = 0\n",
    "model = torch.nn.Linear(57, 1, bias=False, dtype=float)\n",
    "loss_fn = LinearLoss()\n",
    "optimizer=OGDOptimizer(params=model.parameters(),lr=eta)\n",
    "spam_inst=torch.tensor(spam_inst).requires_grad_(True)\n",
    "spam_label=torch.tensor(spam_label,dtype=float).requires_grad_(True)\n",
    "prediction2=[]\n",
    "cum_loss2=0\n",
    "for epoch in range(T):\n",
    "    # Forward pass\n",
    "    outputs = model(spam_inst[epoch])\n",
    "    if outputs[0]>0:\n",
    "        prediction2.append(1)\n",
    "    else:\n",
    "        prediction2.append(-1)\n",
    "        \n",
    "    loss = loss_fn(outputs, spam_label[epoch])\n",
    "    cum_loss2+=loss\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(sklearn.metrics.accuracy_score(spam_label.detach().numpy(), prediction2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
